# Alpha Gen Environment Configuration
# Copy this file to .env and fill in your values

# LLM Configuration (OpenAI-compatible API)
# Provider is inferred from LLM_BASE_URL:
#   - OpenRouter: https://openrouter.ai/api/v1
#   - Ollama: http://localhost:11434/v1
#   - No base_url defaults to OpenRouter (https://openrouter.ai/api/v1)
LLM_MODEL=openrouter/default
LLM_API_KEY=your-api-key-here
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=4096
# Set base_url to override provider:
# LLM_BASE_URL=https://openrouter.ai/api/v1  # OpenRouter (default)
# LLM_BASE_URL=http://localhost:11434/v1      # Ollama

# Vector Store Configuration
VECTOR_STORE_PROVIDER=chroma
VECTOR_STORE_DIR=./data/vector_store
VECTOR_STORE_COLLECTION=alpha_gen_docs
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Scraping Configuration
SCRAPING_TIMEOUT=30
SCRAPING_RETRIES=3
SCRAPING_DELAY=1.0
SCRAPING_HEADLESS=true

# Observability (LangFuse)
LANGFUSE_ENABLED=true
LANGFUSE_PUBLIC_KEY=your-langfuse-public-key
LANGFUSE_SECRET_KEY=your-langfuse-secret-key
LANGFUSE_HOST=https://cloud.langfuse.com

# Application Settings
DEBUG=false
LOG_LEVEL=INFO
